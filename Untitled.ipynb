{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets: (60000, 28, 28) (60000,) 0 255\n",
      "Model: \"mnist\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "fc_1 (Dense)                 (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "fc_2 (Dense)                 (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "epoch:  0 step:  0 loss:  2.3660438\n",
      "epoch:  0 step:  10 loss:  0.671247\n",
      "epoch:  0 step:  20 loss:  0.44614628\n",
      "epoch:  0 step:  30 loss:  0.23227443\n",
      "epoch:  0 step:  40 loss:  0.41198632\n",
      "epoch:  0 step:  50 loss:  0.3414775\n",
      "epoch:  0 step:  60 loss:  0.28191733\n",
      "epoch:  0 step:  70 loss:  0.26134086\n",
      "epoch:  0 step:  80 loss:  0.2508609\n",
      "epoch:  0 step:  90 loss:  0.15164845\n",
      "epoch:  0 step:  100 loss:  0.2267518\n",
      "epoch:  0 step:  110 loss:  0.24160658\n",
      "epoch:  0 step:  120 loss:  0.22581285\n",
      "epoch:  0 step:  130 loss:  0.2861192\n",
      "epoch:  0 step:  140 loss:  0.16891897\n",
      "epoch:  0 step:  150 loss:  0.12842934\n",
      "epoch:  0 step:  160 loss:  0.2488893\n",
      "epoch:  0 step:  170 loss:  0.20293756\n",
      "epoch:  0 step:  180 loss:  0.20147969\n",
      "epoch:  0 step:  190 loss:  0.15781328\n",
      "epoch:  0 step:  200 loss:  0.16488695\n",
      "epoch:  0 step:  210 loss:  0.16026509\n",
      "epoch:  0 step:  220 loss:  0.17484304\n",
      "epoch:  0 step:  230 loss:  0.18477313\n",
      "epoch:  0 step:  240 loss:  0.13063401\n",
      "epoch:  0 step:  250 loss:  0.11773126\n",
      "epoch:  0 step:  260 loss:  0.121324755\n",
      "epoch:  0 step:  270 loss:  0.16646665\n",
      "epoch:  0 step:  280 loss:  0.12641327\n",
      "epoch:  0 step:  290 loss:  0.14167087\n",
      "epoch:  0 step:  300 loss:  0.12061331\n",
      "epoch:  0 step:  310 loss:  0.18192701\n",
      "epoch:  0 step:  320 loss:  0.09204547\n",
      "epoch:  0 step:  330 loss:  0.19193618\n",
      "epoch:  0 step:  340 loss:  0.148139\n",
      "epoch:  0 step:  350 loss:  0.10482593\n",
      "epoch:  0 step:  360 loss:  0.106368944\n",
      "epoch:  0 step:  370 loss:  0.15058899\n",
      "epoch:  0 step:  380 loss:  0.10772082\n",
      "epoch:  0 step:  390 loss:  0.2052418\n",
      "epoch:  0 step:  400 loss:  0.20812379\n",
      "epoch:  0 step:  410 loss:  0.071191676\n",
      "epoch:  0 step:  420 loss:  0.07398522\n",
      "epoch:  0 step:  430 loss:  0.14403184\n",
      "epoch:  0 step:  440 loss:  0.18485814\n",
      "epoch:  0 step:  450 loss:  0.05146931\n",
      "epoch:  0 step:  460 loss:  0.06282049\n",
      "第0步的阶段精度是： 0.9921875\n",
      "第20步的阶段精度是： 0.9538690476190477\n",
      "第40步的阶段精度是： 0.9557926829268293\n",
      "第60步的阶段精度是： 0.9641393442622951\n",
      "epoch 0 test acc:  0.9671\n",
      "WARNING:tensorflow:From /home/marstao/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./model/tf_savedmodel/assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, optimizers\n",
    "\n",
    "\n",
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    x is a simple image, not a batch\n",
    "    \"\"\"\n",
    "    x = tf.expand_dims(x, axis=-1)\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    # x = tf.reshape(x, [28 * 28])\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    y = tf.one_hot(y, depth=10)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "batchsz = 128\n",
    "\n",
    "\n",
    "def train():\n",
    "    # 可以直接使用datasets.mnist.load_data()，如果网络好，可以连接外网，\n",
    "    # 如果下载不了，可以自己先下载文件\n",
    "    (x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "    print('datasets:', x.shape, y.shape, x.min(), x.max())\n",
    "\n",
    "    db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    db = db.map(preprocess).shuffle(10000).batch(batchsz)\n",
    "    ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "    ds_val = ds_val.map(preprocess).batch(batchsz)\n",
    "\n",
    "    # sample = next(iter(db))\n",
    "    # print(sample[0].shape, sample[1].shape)\n",
    "    inputs = tf.keras.Input(shape=(28, 28, 1), name='input')\n",
    "    # [28, 28, 1] => [28, 28, 64]\n",
    "    input = tf.keras.layers.Flatten(name=\"flatten\")(inputs)\n",
    "    fc_1 = tf.keras.layers.Dense(512, activation='relu', name='fc_1')(input)\n",
    "    fc_2 = tf.keras.layers.Dense(256, activation='relu', name='fc_2')(fc_1)\n",
    "    pred = tf.keras.layers.Dense(10, activation='softmax', name='output')(fc_2)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=pred, name='mnist')\n",
    "    model.summary()\n",
    "    Loss = []\n",
    "    Acc = []\n",
    "    optimizer = optimizers.Adam(0.001)\n",
    "    # epoches = 5\n",
    "    for epoch in range(1):\n",
    "        # 创建用于测试精度的参数\n",
    "        total_num = 0\n",
    "        total_correct = 0\n",
    "        for step, (x, y) in enumerate(db):\n",
    "            with tf.GradientTape() as tape:\n",
    "\n",
    "                pred = model(x)\n",
    "                loss = tf.keras.losses.categorical_crossentropy(y_pred=pred,\n",
    "                                                                y_true=y,\n",
    "                                                                from_logits=False)\n",
    "                loss = tf.reduce_mean(loss)\n",
    "                grades = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grades, model.trainable_variables))\n",
    "                # 输出loss值\n",
    "            if step % 10 == 0:\n",
    "                print(\"epoch: \", epoch, \"step: \", step, \"loss: \", loss.numpy())\n",
    "                Loss.append(loss)\n",
    "\n",
    "        # 计算精度，将全连接层的输出转化为概率值输出\n",
    "        for step, (x_val, y_val) in enumerate(ds_val):\n",
    "            # 预测测试集的输出\n",
    "\n",
    "            pred = model(x_val)\n",
    "            # pred = tf.nn.softmax(pred, axis=1)\n",
    "            pred = tf.argmax(pred, axis=1)\n",
    "            pred = tf.cast(pred, tf.int32)\n",
    "            y_val = tf.argmax(y_val, axis=1)\n",
    "            y_val = tf.cast(y_val, tf.int32)\n",
    "            correct = tf.equal(pred, y_val)\n",
    "            correct = tf.cast(correct, tf.int32)\n",
    "            correct = tf.reduce_sum(correct)\n",
    "            total_correct += int(correct)\n",
    "            total_num += x_val.shape[0]\n",
    "            if step % 20 == 0:\n",
    "                acc_step = total_correct / total_num\n",
    "                print(\"第\" + str(step) + \"步的阶段精度是：\", acc_step)\n",
    "                Acc.append(float(acc_step))\n",
    "\n",
    "        acc = total_correct / total_num\n",
    "        print(\"epoch %d test acc: \" % epoch, acc)\n",
    "    # 方式1：\n",
    "    model.save('./model/tf_savedmodel', save_format='tf')\n",
    "    # 方式2：\n",
    "    # tf.saved_model.save(obj=model, export_dir=\"./model/\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (5, 1, 5)\n",
      "INFO:tensorflow:Loaded TensorRT version: (5, 1, 5)\n",
      "INFO:tensorflow:Running against TensorRT version 5.1.5\n",
      "INFO:tensorflow:Assets written to: ./model/trt_savedmodel/assets\n",
      "tensorrt times:  20.840883255004883  ms\n",
      "prediction result:  [7]   |   true result:  7\n",
      "tensorrt times:  0.629425048828125  ms\n",
      "prediction result:  [2]   |   true result:  2\n",
      "tensorrt times:  0.42176246643066406  ms\n",
      "prediction result:  [1]   |   true result:  1\n",
      "tensorrt times:  0.5562305450439453  ms\n",
      "prediction result:  [0]   |   true result:  0\n",
      "tensorrt times:  0.4444122314453125  ms\n",
      "prediction result:  [4]   |   true result:  4\n",
      "tensorrt times:  2.286672592163086  ms\n",
      "prediction result:  [1]   |   true result:  1\n",
      "tensorrt times:  0.9849071502685547  ms\n",
      "prediction result:  [4]   |   true result:  4\n",
      "tensorrt times:  0.560760498046875  ms\n",
      "prediction result:  [9]   |   true result:  9\n",
      "tensorrt times:  0.6091594696044922  ms\n",
      "prediction result:  [6]   |   true result:  5\n",
      "tensorrt times:  0.6508827209472656  ms\n",
      "prediction result:  [9]   |   true result:  9\n",
      "tensorrt times:  0.41222572326660156  ms\n",
      "prediction result:  [0]   |   true result:  0\n",
      "tensorrt times:  0.6241798400878906  ms\n",
      "prediction result:  [6]   |   true result:  6\n",
      "tensorrt times:  0.5738735198974609  ms\n",
      "prediction result:  [9]   |   true result:  9\n",
      "tensorrt times:  0.5636215209960938  ms\n",
      "prediction result:  [0]   |   true result:  0\n",
      "tensorrt times:  0.5707740783691406  ms\n",
      "prediction result:  [1]   |   true result:  1\n",
      "tensorrt times:  0.5714893341064453  ms\n",
      "prediction result:  [5]   |   true result:  5\n",
      "tensorrt times:  0.4944801330566406  ms\n",
      "prediction result:  [9]   |   true result:  9\n",
      "tensorrt times:  0.4858970642089844  ms\n",
      "prediction result:  [7]   |   true result:  7\n",
      "tensorrt times:  0.6029605865478516  ms\n",
      "prediction result:  [3]   |   true result:  3\n",
      "tensorrt times:  0.522613525390625  ms\n",
      "prediction result:  [4]   |   true result:  4\n",
      "tensorrt times:  0.5631446838378906  ms\n",
      "prediction result:  [9]   |   true result:  9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from tensorflow.keras import datasets, optimizers\n",
    "\n",
    "params = trt.DEFAULT_TRT_CONVERSION_PARAMS\n",
    "params._replace(precision_mode=trt.TrtPrecisionMode.FP32)\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir=\"./model/tf_savedmodel\", conversion_params=params)\n",
    "# 完成转换,但是此时没有进行优化,优化在执行推理时完成\n",
    "converter.convert()\n",
    "converter.save('./model/trt_savedmodel')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "x_test = x_test.astype('float32')\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_test /= 255\n",
    "\n",
    "# 读取模型\n",
    "saved_model_loaded = tf.saved_model.load(\"./model/trt_savedmodel\", tags=[trt.tag_constants.SERVING])\n",
    "# 获取推理函数,也可以使用saved_model_loaded.signatures['serving_default']\n",
    "graph_func = saved_model_loaded.signatures[trt.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "# 将模型中的变量变成常量,这一步可以省略,直接调用graph_func也行\n",
    "frozen_func = trt.convert_to_constants.convert_variables_to_constants_v2(graph_func)\n",
    "\n",
    "count = 20\n",
    "for x, y in zip(x_test, y_test):\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    start = time.time()\n",
    "    # frozen_func(x)返回值是个列表\n",
    "    # 列表中含有一个元素，就是输出tensor，使用.numpy()将其转化为numpy格式\n",
    "    output = frozen_func(x)[0].numpy()\n",
    "    end = time.time()\n",
    "    times = (end - start) * 1000.0\n",
    "    print(\"tensorrt times: \", times, \" ms\")\n",
    "    result = np.argmax(output, 1)\n",
    "    print(\"prediction result: \", result, \"  |  \", \"true result: \", y)\n",
    "\n",
    "    if count == 0:\n",
    "        break\n",
    "    count -= 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
